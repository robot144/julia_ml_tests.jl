{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional Generative Adversarial Network (DCGAN)\n",
    "Train a DCGAN to generate MNIST images\n",
    "\n",
    "See [this repo](https://github.com/FluxML/model-zoo/tree/master/vision/cdcgan_mnist), [this pytorch tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html), and [this](https://github.com/soumith/ganhacks) for useful tricks.\n",
    "\n",
    "[Origianl GAN paper](https://arxiv.org/abs/1406.2661)\n",
    "\n",
    "[DCGAN paper](https://arxiv.org/pdf/1511.06434.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Julia 1.9.2' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "using Flux\n",
    "using MLDatasets\n",
    "using Random\n",
    "using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128  \n",
    "latent_dim = 100\n",
    "epochs = 30\n",
    "n_val = 16\n",
    "lr_disc = 0.0002\n",
    "lr_gen = 0.0002\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 60000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MNIST dataset and reshape + normalize to [-1,1]\n",
    "images = MLDatasets.MNIST(:train).features\n",
    "image_tensor = reshape(@.(2f0*images - 1f0), 28, 28, 1, :)\n",
    "size(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000-element Vector{Float64}:\n",
       " 0.9900133013725281\n",
       " 0.9000288128852845\n",
       " 0.9238494038581848\n",
       " 0.9546479403972626\n",
       " 0.9118001341819764\n",
       " 0.9931084394454956\n",
       " 0.9013398230075836\n",
       " 0.978172916173935\n",
       " 0.999093782901764\n",
       " 0.9117977380752563\n",
       " 0.9535072267055512\n",
       " 0.9035910665988922\n",
       " 0.9979776263237\n",
       " ⋮\n",
       " 0.9675454676151276\n",
       " 0.9204791843891144\n",
       " 0.9304541230201722\n",
       " 0.9807366907596589\n",
       " 0.9015099227428437\n",
       " 0.9300561308860779\n",
       " 0.9478922963142395\n",
       " 0.9884008467197418\n",
       " 0.9303670108318329\n",
       " 0.9534220278263092\n",
       " 0.9790423393249512\n",
       " 0.9586935639381409"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels to use for real images. As noted in the useful tricks, it helps to set real=0 and fake=1 and using soft labels: real=[0,1], fake=[0.9,1]\n",
    "real_labels = 0.1.*rand(Float32, size(image_tensor)[end])\n",
    "fake_labels = 0.1.*rand(Float32, size(image_tensor)[end]).+0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100×16 Matrix{Float32}:\n",
       "  0.00724127   1.62873     …   0.0110928  -1.04959      0.536255\n",
       "  0.348034     1.25897         0.680787   -0.617239    -0.818312\n",
       " -0.610398     0.302688        0.748166    0.00465741   1.34457\n",
       "  0.806511    -0.917159       -0.152679   -0.628985     1.14415\n",
       " -2.13614      0.791357        0.319659   -0.172842    -0.816172\n",
       "  2.64086      0.14931     …  -0.185784   -1.15927      0.98001\n",
       " -0.131726     0.378519        0.689256   -1.27684      2.54643\n",
       "  0.316592     0.609034        0.804003   -0.935041     0.0113185\n",
       " -0.0887196   -0.382533       -1.07647    -0.651147    -0.0727658\n",
       " -1.62575     -0.297545        1.05755     0.252879    -0.560706\n",
       "  0.690676     0.00189033  …   0.466039   -0.496895    -0.224915\n",
       " -0.15587      0.947364       -0.405452   -1.69413      1.23672\n",
       "  0.824651    -0.19469         0.34773    -0.828632    -0.181304\n",
       "  ⋮                        ⋱                            ⋮\n",
       "  1.22846     -0.148749       -0.173922   -1.36994      0.922575\n",
       "  0.439776     1.48073        -1.53274    -0.236978    -0.753705\n",
       "  0.10915      0.396264    …   0.491584   -0.603415     2.18672\n",
       "  0.773792    -1.94292        -0.958903   -1.21815     -0.0372233\n",
       " -0.102123    -0.540404        0.139279   -0.563989     0.597728\n",
       "  0.706704     0.0174224       1.21336     0.167935     0.311036\n",
       "  0.902536     0.751082       -0.68        0.286958     1.52728\n",
       "  0.00701478   0.660708    …   0.832498   -0.404035    -0.124953\n",
       " -0.715308     0.102804       -0.263369   -0.108206     0.317315\n",
       "  0.992074    -1.53225         1.65754     0.194794    -1.00728\n",
       " -2.05722      1.6179         -0.623098    1.40947     -0.446111\n",
       " -0.84652      0.076566        1.22191    -1.20045      0.768948"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fake but fixed noise to use for monitoring training process\n",
    "fixed_noise = randn(Float32,(latent_dim, n_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dcgan_init (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializer for weights\n",
    "dcgan_init(shape...) = randn(Float32,shape...)* 0.02f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discriminator_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to build discriminator and its loss function\n",
    "function Discriminator()\n",
    "    return Chain(\n",
    "        Conv((4,4),1 => 64; stride=2, pad=1, init=dcgan_init),\n",
    "        x->leakyrelu.(x, 0.2f0),\n",
    "        Dropout(0.25),\n",
    "        Conv((4,4), 64 => 128; stride=2, pad=1, init=dcgan_init),\n",
    "        x->leakyrelu.(x, 0.2f0),\n",
    "        Dropout(0.25),\n",
    "        x->reshape(x,7*7*128,:),\n",
    "        Dense(7*7*128=>1)\n",
    "    )\n",
    "end\n",
    "\n",
    "function discriminator_loss(real_output, fake_output, real_labels, fake_labels)\n",
    "    real_loss = logitbinarycrossentropy(real_output, real_labels)\n",
    "    fake_loss = logitbinarycrossentropy(fake_output, fake_labels)\n",
    "    return real_loss+fake_loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator (generic function with 1 method)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to build generator\n",
    "function Generator(latent_dim::Int)\n",
    "    return Chain(\n",
    "        Dense(latent_dim, 7*7*256),\n",
    "        BatchNorm(7*7*256, relu),\n",
    "        x->reshape(x, 7, 7, 256, :),\n",
    "        ConvTranspose((5,5), 256 => 128; stride=1, pad=2, init=dcgan_init),\n",
    "        BatchNorm(128,relu),\n",
    "        ConvTranspose((4,4), 128 => 64; stride=2, pad=1, init=dcgan_init),\n",
    "        BatchNorm(64,relu),\n",
    "        ConvTranspose((4,4), 64 => 1, stride=2, pad=1, init=dcgan_init),\n",
    "        x->tanh.(x)\n",
    "    )\n",
    "end\n",
    "\n",
    "generator_loss(fake_output) = logitbinarycrossentropy(fake_output, real_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Conv((4, 4), 1 => 64, pad=1, stride=2),  \u001b[90m# 1_088 parameters\u001b[39m\n",
       "  var\"#3#6\"(),\n",
       "  Dropout(0.25),\n",
       "  Conv((4, 4), 64 => 128, pad=1, stride=2),  \u001b[90m# 131_200 parameters\u001b[39m\n",
       "  var\"#4#7\"(),\n",
       "  Dropout(0.25),\n",
       "  var\"#5#8\"(),\n",
       "  Dense(6272 => 1),                     \u001b[90m# 6_273 parameters\u001b[39m\n",
       ") \u001b[90m                  # Total: 6 arrays, \u001b[39m138_561 parameters, 542.145 KiB."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = Generator(latent_dim)\n",
    "disc = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(layers = ((weight = \u001b[32mLeaf(Adam(0.0002, (0.9, 0.999), 1.0e-8), \u001b[39m(Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, bias = \u001b[32mLeaf(Adam(0.0002, (0.9, 0.999), 1.0e-8), \u001b[39m(Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, σ = ()), (λ = (), β = \u001b[32mLeaf(Adam(0.0002, (0.9, 0.999), 1.0e-8), \u001b[39m(Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, γ = \u001b[32mLeaf(Adam(0.0002, (0.9, 0.999), 1.0e-8), \u001b[39m(Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, μ = (), σ² = (), ϵ = (), momentum = (), affine = (), track_stats = (), active = (), chs = ()), (), (σ = (), weight = \u001b[32mLeaf(Adam(0.0002, (0.9, 0.999), 1.0e-8), \u001b[39m([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; … ;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; … ;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; … ;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; … ;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; … ;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; … ;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; … ;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; … ;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; … ;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; … ;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; … ;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; … ;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; … ;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, bias = \u001b[32mLeaf(Adam(0.0002, (0.9, 0.999), 1.0e-8), \u001b[39m(Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, stride = ((), ()), pad = ((), (), (), ()), dilation = ((), ()), groups = ()), (λ = (), β = \u001b[32mLeaf(Adam(0.0002, (0.9, 0.999), 1.0e-8), \u001b[39m(Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, γ = \u001b[32mLeaf(Adam(0.0002, (0.9, 0.999), 1.0e-8), \u001b[39m(Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, μ = (), σ² = (), ϵ = (), momentum = (), affine = (), track_stats = (), active = (), chs = ()), (σ = (), weight = \u001b[32mLeaf(Adam(0.0002, (0.9, 0.999), 1.0e-8), \u001b[39m([0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; … ;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; … ;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; … ;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;;; … ;;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; … ;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; … ;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; … ;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0], [0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; … ;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; … ;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; … ;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;;; … ;;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; … ;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; … ;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; … ;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, bias = \u001b[32mLeaf(Adam(0.0002, (0.9, 0.999), 1.0e-8), \u001b[39m(Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, stride = ((), ()), pad = ((), (), (), ()), dilation = ((), ()), groups = ()), (λ = (), β = \u001b[32mLeaf(Adam(0.0002, (0.9, 0.999), 1.0e-8), \u001b[39m(Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, γ = \u001b[32mLeaf(Adam(0.0002, (0.9, 0.999), 1.0e-8), \u001b[39m(Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, μ = (), σ² = (), ϵ = (), momentum = (), affine = (), track_stats = (), active = (), chs = ()), (σ = (), weight = \u001b[32mLeaf(Adam(0.0002, (0.9, 0.999), 1.0e-8), \u001b[39m([0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;;; … ;;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0], [0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;;; … ;;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0;;;; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, bias = \u001b[32mLeaf(Adam(0.0002, (0.9, 0.999), 1.0e-8), \u001b[39m(Float32[0.0], Float32[0.0], (0.9, 0.999))\u001b[32m)\u001b[39m, stride = ((), ()), pad = ((), (), (), ()), dilation = ((), ()), groups = ()), ()),)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_opt = Flux.setup(Adam(lr_disc), disc)\n",
    "gen_opt = Flux.setup(Adam(lr_gen), gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28×28×1×16 Array{Float32, 4}:\n",
       "[:, :, 1, 1] =\n",
       " -0.000745898   0.000961913  -0.00471434   …   0.000640112   0.00068877\n",
       " -0.00465893    0.00374137   -0.00296304      -0.0075544    -0.000739787\n",
       " -0.00108253    0.0107205    -0.00653486      -0.00108507   -0.00100319\n",
       "  0.00302239    0.000982488   0.00143781      -0.00777687    0.00421835\n",
       " -0.00424564    0.00380425   -0.00757325       0.00214467   -0.000574293\n",
       " -0.000369982   0.00462612   -0.00625899   …  -0.00943098    0.00575584\n",
       "  0.00100281    0.0186923    -0.00964474       0.00501088   -0.00147504\n",
       "  0.000980961  -7.88132f-7   -0.0095213       -0.00301693    0.00448221\n",
       " -0.00338154    0.00168633   -0.0149562        3.35285f-5   -0.0020573\n",
       " -0.00353171    0.00735607   -0.00125396      -0.00790458    0.00079305\n",
       "  0.0016785     0.00890716    0.00138324   …   0.00455573   -0.00318709\n",
       "  0.000800399  -0.00116952    0.00121243      -0.00751017    0.00331199\n",
       " -0.00263419   -0.00467495   -0.0127132        0.00148931   -0.00112025\n",
       "  ⋮                                        ⋱                \n",
       " -0.00337175   -0.00375542   -0.00922747       0.00368705   -0.0046153\n",
       " -0.00418437    0.0106111    -0.0043413       -0.00417081    0.00422075\n",
       "  0.000406813   0.0107589     0.00121272       0.00835237   -0.00377609\n",
       "  0.00161823    0.00171097    0.00308466      -0.00964145   -0.000548326\n",
       " -0.00166194   -7.89108f-5   -0.00590312   …   0.00324954   -0.00357997\n",
       " -0.00189797   -0.00529235   -0.00746834      -0.00571187   -0.00288496\n",
       "  0.000857114   0.0107813     0.00148095       0.00685557   -0.00481449\n",
       "  0.00267076    0.0105352     0.000784995     -0.00120371   -0.00211264\n",
       " -0.000839989  -0.00118869   -0.000574363      0.00519721   -0.00411487\n",
       " -0.00218022   -0.00103758   -0.000628617  …  -0.00897783    0.00125141\n",
       "  0.00287023    0.0103776     0.00666279       0.00532362   -0.00245835\n",
       " -2.0715f-5     0.00365347    0.000868486     -0.00302899   -0.000470522\n",
       "\n",
       "[:, :, 1, 2] =\n",
       " -0.00127046    0.00310533   -0.00290833   …  -0.00213644   -0.00135873\n",
       " -0.00442629    0.00292913   -0.00638894      -0.00663251    0.00254921\n",
       " -0.00129013    0.00951234   -0.00378215       0.00159403   -0.00308176\n",
       " -0.00212774    0.00223777    0.00272657       0.000977863   0.000270992\n",
       " -0.0048739    -0.00309751   -0.005867        -0.00709992    0.000399624\n",
       " -0.00405008    0.00553261   -0.00671651   …  -0.00826172    8.71436f-5\n",
       " -0.00226665    0.00752814   -0.00297719       0.00234251   -0.00216262\n",
       "  0.000355479   0.00462863   -0.000551619     -0.00494331    0.00161024\n",
       " -0.0030185    -0.00888871   -0.00513931       0.00182916    0.00103396\n",
       " -0.00758703    0.011529      0.000391342     -0.00167713    0.00335997\n",
       "  0.000781629   0.00780977   -0.00231627   …   0.00340573   -0.00718086\n",
       "  0.00203778    0.00545611   -0.0027115        0.000903793   0.00159389\n",
       " -0.000519016   0.002784     -0.0160997        0.0046208    -0.00263029\n",
       "  ⋮                                        ⋱                \n",
       " -0.00462984    0.000766911  -0.012579        -0.00232164   -0.00327435\n",
       " -0.00182132    0.00180571   -0.00819153      -0.00517428    0.0030412\n",
       "  0.000970562   0.00534536    0.00513067       0.0105286    -0.0018084\n",
       " -0.000257859   0.00772887   -0.00469997      -0.00310644    0.00406142\n",
       " -0.00107373   -0.00892577   -0.00367398   …   0.00185331    0.000909273\n",
       " -0.0077572    -0.00113738   -0.00496946      -0.0181577     0.000615649\n",
       "  0.00126072    0.0171312    -0.00229213       0.0114294    -0.00140626\n",
       " -0.000155996   0.00225404    0.002324        -0.00781166    0.000688926\n",
       " -0.00169338    0.00424466    0.00035305       0.00219202   -0.00192596\n",
       " -0.00100664    0.000666529  -0.00468373   …  -0.00630356   -0.00117512\n",
       "  0.000912127   0.00196016   -0.00114243       0.00928199   -0.00530652\n",
       "  0.000164454  -0.00211307    0.000282325      0.00146071    0.000390763\n",
       "\n",
       "[:, :, 1, 3] =\n",
       " -0.00127814    0.00398082   -0.00306969   …   0.00105455  -0.00121264\n",
       " -0.00303287    0.00201173   -0.010556        -0.0111993    0.000111577\n",
       " -0.00201511    0.0105756    -0.00654987      -0.00269945  -0.000751922\n",
       "  0.000184174  -0.00251506   -0.00160646      -0.0115923    0.00186788\n",
       " -0.000792788  -0.000334355  -0.00512917      -0.00378601  -0.00128539\n",
       " -0.00293736   -0.000403293  -0.000131076  …  -0.00809492   0.000502089\n",
       " -4.7221f-5     0.0120095     0.00214059       0.00584152  -0.00336202\n",
       "  0.000946416  -0.000410028  -0.00133567      -0.00375732   0.00189236\n",
       " -0.0020394     0.000898168  -0.000840486     -0.00268369  -0.00549717\n",
       " -0.0125008     0.00240538   -0.00729255      -0.0116247    0.00250692\n",
       "  0.000577533   0.0145126    -0.00817692   …   0.00846372  -0.00220824\n",
       "  0.0044021     0.00601603    0.00174134      -0.0032363    0.00149602\n",
       " -0.00308444   -0.00638765   -0.00271997       0.00426284  -0.00335121\n",
       "  ⋮                                        ⋱               \n",
       "  0.0025498    -0.000435201  -0.00111287       0.00324434  -0.00601862\n",
       " -0.00835827    0.000551255  -0.00762674      -0.0106366   -0.00121049\n",
       "  0.00169594    0.00764153   -0.00184821       0.00565173  -0.00515743\n",
       " -0.00317248    0.00654429    0.00390016      -0.00357525   0.00378795\n",
       " -0.00444201   -0.00601194   -0.00606537   …  -0.00318971  -0.00365942\n",
       " -0.00197417   -1.42062f-5   -0.00631951      -0.0113665    0.00142382\n",
       "  0.00168157    0.0127878    -0.0035398        0.0139553   -0.00237419\n",
       " -0.00137774    0.00902193    0.00246637      -0.00902426  -0.00178508\n",
       "  0.000259071  -0.000315286  -0.00526267      -0.00106478  -0.00443222\n",
       " -0.00500411   -0.00322559   -0.00502915   …  -0.00498949   0.000995181\n",
       "  0.00148447    0.00633044   -0.00227117       0.00855988  -0.00341381\n",
       "  0.000872391  -0.000796073   0.00254042      -0.00148879  -2.74585f-5\n",
       "\n",
       ";;;; … \n",
       "\n",
       "[:, :, 1, 14] =\n",
       " -0.00122699   -0.00121435   -0.00406254   …   0.00252343   -0.00373329\n",
       " -0.00381278    0.00253823   -0.00295044      -0.00847996    0.00439091\n",
       " -0.00191993    0.0102149    -0.00353748       0.00168871   -0.00250897\n",
       " -0.000958207   0.00400219   -0.00163358      -0.00706487    0.00313737\n",
       " -0.00133715    0.00753047   -0.00665623      -0.00400156    0.0045223\n",
       " -0.00375038    0.00498298   -0.00768798   …  -0.00760212   -0.00351935\n",
       "  0.0022511     0.0152451    -0.00386125       0.00645432    0.00139905\n",
       "  0.00130821   -0.00283449   -0.00434264      -0.000403782  -0.00376373\n",
       " -0.000508581   0.00950624   -0.00721232       0.00553425   -0.00232065\n",
       " -0.00533426    0.00896585   -0.002489        -0.00595122   -0.000803682\n",
       "  0.00139068    0.00956704   -0.000874105  …   0.0119342    -0.000662855\n",
       " -0.00232203    0.00292574   -0.0152114       -0.00819794    0.00420346\n",
       " -0.00412135    0.00195605   -0.00538053       0.006431     -0.00175536\n",
       "  ⋮                                        ⋱                \n",
       " -0.00382037   -0.00113512    0.00185657      -0.00254969   -0.00676656\n",
       "  0.000942666   0.00589676   -0.00847642      -0.00697972    0.000971349\n",
       "  0.00407035    0.0162575    -0.00528503       0.00146881   -0.00617892\n",
       "  0.00265438   -0.000285398  -0.0062365       -0.000986362   0.00153457\n",
       "  0.00100296   -0.000295232  -0.00694964   …  -0.0039623    -0.00670787\n",
       " -0.00456372    0.000302019  -0.00939055      -0.00810032    0.00127507\n",
       "  0.000276124   0.00382663   -0.00291648       0.0141901    -0.00646937\n",
       "  0.00175505   -4.34578f-6   -0.0039227       -0.00773707   -0.000631711\n",
       "  0.000466091  -0.00286497   -0.00908736       0.00342491   -0.00408101\n",
       " -0.00459614   -0.00165191   -0.0030638    …  -0.00148934   -0.00131552\n",
       "  0.00267925    0.0136207     0.00223178       0.00457141   -0.00343386\n",
       " -0.00109996   -0.000255465   0.00100873      -0.00163096   -0.000578054\n",
       "\n",
       "[:, :, 1, 15] =\n",
       " -0.000976859   0.000360796  -0.00347865   …  -0.00040668   -0.00155867\n",
       " -0.00279065    0.00664015   -0.00559692      -0.008517      0.00118037\n",
       "  0.00100322    0.0104334    -0.0048833        0.00361328   -0.00206807\n",
       "  0.00118534    0.00409596   -0.00477117      -0.00301169    0.00193295\n",
       " -6.24999f-5    0.00185443    0.000182872     -0.00261717   -0.00225948\n",
       " -0.00296944    0.00382068   -0.00590431   …  -0.00962146    7.45394f-5\n",
       " -0.000806049   0.00172957   -0.00171754       0.00499816   -0.00350909\n",
       "  0.00113791    0.00199732   -0.004685        -0.00388937    0.00409134\n",
       "  0.000220715   0.00152804   -0.00355849       0.000577073  -0.00144142\n",
       " -0.00171674    0.00475292   -0.0131488       -0.00717482    0.00372304\n",
       " -0.00167125    0.0121626     0.00221928   …   0.00291363   -0.00136618\n",
       " -0.000696456   0.00345363   -0.00335588      -0.000682721   0.00639713\n",
       "  0.00120369    0.00352712   -0.0117581       -0.00454437   -0.00561988\n",
       "  ⋮                                        ⋱                \n",
       " -0.00488143   -0.008206      0.00163474       0.000321081  -0.00187666\n",
       " -0.00205008    0.00434771   -0.00470632      -0.00650529   -0.000230208\n",
       "  0.0016098     0.0117469     0.000168204      0.00672561   -0.000425752\n",
       " -0.00155279    0.00438085   -0.00287205      -0.00545548    0.00408587\n",
       " -0.00263762    0.00856582   -0.00437715   …  -0.00155485   -0.0027456\n",
       " -0.00585394   -0.00156371   -0.00366365      -0.0105435     0.0018888\n",
       "  0.000693678   0.0157822     0.00172008       0.00906282   -0.00217785\n",
       "  0.00442693    0.0003783    -0.00366448      -0.0037194    -0.000199029\n",
       " -0.00181       0.00241726   -0.0105253       -0.0018986    -0.00363637\n",
       " -0.00114166    0.00233913   -0.0070545    …  -0.00550565   -0.00128602\n",
       "  0.00138756    0.00954229    0.000273903      0.0152235    -0.000720897\n",
       " -0.000420213   0.00150237   -0.000475626     -0.000533597   0.000803344\n",
       "\n",
       "[:, :, 1, 16] =\n",
       " -0.00262595   -0.00331124   -0.00406494   …   0.000814502  -0.00234956\n",
       " -0.00181154    0.00327618   -0.00210972      -0.01115       0.00143029\n",
       " -0.00216012    0.00837041   -0.00384568      -0.00164834    0.00112358\n",
       "  0.000554473   0.00358987    0.00108123      -0.0010395     0.00167544\n",
       "  0.000500655   0.00383673   -0.00240272      -0.00284942   -0.00472038\n",
       " -0.00239888    0.00184802   -0.00659517   …  -0.0089189     0.000803648\n",
       "  0.000532774   0.0164743    -0.00443094       0.00765603    0.00103867\n",
       "  0.0021674     0.00209646   -0.00302573      -0.00342347    0.0011954\n",
       " -0.00184326   -0.000378418  -0.00817838      -0.00310463   -0.00177371\n",
       " -0.00434807    0.00618634   -0.0067046       -0.00466925   -0.000926621\n",
       "  0.00353648    0.00781554   -0.00111411   …   0.00587221   -0.00308729\n",
       " -0.00268794   -0.00487046   -0.0054167       -0.00913672   -0.00136349\n",
       " -0.00302852   -0.00365791   -0.00542898       0.00328915   -0.00555738\n",
       "  ⋮                                        ⋱                \n",
       " -0.00370427    0.00107651   -0.00735311       0.00469894   -0.00607831\n",
       " -0.00424727   -0.00274873    0.000322382     -0.0142078    -0.00355245\n",
       "  0.00158955    0.0156885    -0.00241035       0.013153     -0.00334604\n",
       "  0.00359961    0.00846306   -0.00590185      -0.00970456   -0.000706088\n",
       " -0.00157356   -0.00545403    0.000282299  …   0.00781764   -0.00349409\n",
       " -0.00329296    0.00188694   -0.00849761      -0.0088386     0.00315338\n",
       " -0.000667911   0.00665502    0.00551309       0.00411295   -0.00280278\n",
       " -0.0020494     0.00814732   -0.00721826      -0.00566706    0.00264312\n",
       "  0.000721313   0.00119603   -0.00659629       0.010931     -0.00261207\n",
       " -0.00202498    0.00351804   -0.00263856   …  -0.0055956    -0.000163159\n",
       " -0.00141658    0.00530631   -0.00190429       0.00916246   -0.00117911\n",
       "  0.00016788   -0.00107909    0.00444764       6.73042f-5    0.00075359"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(fixed_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×4 Matrix{Float32}:\n",
       " -0.0306821  -0.00460608  0.014002  -0.0174576"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc(image_tensor[:,:,:,1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
