{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a network against data from the Burgers equation\n",
    "\n",
    "Training a Convolutional Neural Network (CNN) with data from the Burgers equation. See model_1d folder for the code that generated the data.\n",
    "\n",
    "A simple setup for a surrogate model predicts the next time-step from the current one. This all starts from a mathematical model, which tyically involves Patial Differential Equations, but here we just collect the dynamic variables in the model in a vector $x$ at discrete times $t_0,t_1,\\ldots,t_K$ and denote these as $x_k$. We can represent the numerical model as:\n",
    "\n",
    "$x_{k+1}=M(x_k)$, starting with given initial condition $x_0$\n",
    "\n",
    "Next, we run the numerical model and collect $x_0,x_1,\\ldots,x_K$ as training data for our Machine Learning (ML) model. The aim of the ML model will be to approximate the numerical model, and we'll call it a surrogate model. It's main purpose is to have a faster but slightly less accurate version of the model. We denote the surrogate model as: \n",
    "\n",
    "$\\hat{x}_{k+1}=\\hat{M}(\\hat{x}_k,\\theta)$\n",
    "\n",
    "starting with $\\hat{x}_0=x_0$, which is the true initial condition.\n",
    "\n",
    "This model has $\\hat{x}_k$ as input and $x_{k+1}$ as output, and $\\theta$ is a vector of parameters of the ML model to be estimated. For a given vector of parameters, one can sequentially compute $\\hat{x}_1$, $\\hat{x}_2$, $\\hat{x}_3$, etc. This is called a rollout.\n",
    "\n",
    "## Training\n",
    "\n",
    "For training the most basic approach is to use one-step-ahead predictions. This means that the target is to accurately approximate the output of the numerical model. We can write this as a loss function:\n",
    "\n",
    "$J(\\theta) = \\sum_{k=1}^{K-1} | x_{k+1} - \\hat{M}(x_k,\\theta)|^2$\n",
    "\n",
    "Viewed as a supervised learning method, we have the generated data $x_k$ as inputs and $x_{k+1}$ as outputs. As is common in such cases the input data are collected in an input array $X$ and an output array $Y$ that consist of:\n",
    "\n",
    "$X=[x_0,x_1,\\ldots,x_{K-1}]$\n",
    "$Y=[x_1,x_2,\\ldots,x_{K}]$ \n",
    "\n",
    "We can generalize $\\hat{M}$ to matrices to obtain:\n",
    "\n",
    "$Y \\approx \\hat{M}(X,\\theta)$\n",
    "\n",
    "Unfortunately there is no guarantee that reasonably accurate one-step-ahead predictions lead to accurate rollouts, since the errors can accumulate quickly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/src_nobackup/julia_ml_tests.jl.git/training_1d_flux`\n"
     ]
    }
   ],
   "source": [
    "# Load Packages\n",
    "\n",
    "# swithch to the directory where this script is located\n",
    "cd(@__DIR__)\n",
    "\n",
    "# Packages\n",
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "#Pkg.instantiate()\n",
    "using Flux\n",
    "using BSON\n",
    "using Plots, Measures\n",
    "using JLD2\n",
    "\n",
    "# optional gpu usage\n",
    "const use_gpu = false\n",
    "if use_gpu\n",
    "    using CUDA\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Excessive output truncated after 582758 bytes."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../model_1d/burgers1d_periodic.jld2\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "\n",
    "input_file = joinpath(\"..\", \"model_1d\", \"burgers1d_periodic.jld2\")\n",
    "if !isfile(input_file)\n",
    "    println(\"Data file not found: $input_file\")\n",
    "end\n",
    "println(\"Loading data from $input_file\")\n",
    "data=load(input_file)\n",
    "\n",
    "# Convert data to input and output arrays\n",
    "\n",
    "n_times=length(data[\"solution\"])\n",
    "n_points=length(data[\"solution\"][1])\n",
    "\n",
    "# Create inputs X and outputs Y\n",
    "# u is the solution, t is the time, x is the spatial coordinate\n",
    "X = zeros(Float32,n_points,1,n_times-1) # Float32 for GPU compatibility, 1 channel since only one variable u\n",
    "Y = zeros(Float32,n_points,1,n_times-1) \n",
    "\n",
    "for t in 1:n_times-1\n",
    "    X[:,:,t] .= data[\"solution\"][t]\n",
    "    Y[:,:,t] .= data[\"solution\"][t+1]\n",
    "end\n",
    "\n",
    "@show X, size(X)\n",
    "@show Y, size(Y)\n",
    "\n",
    "# some metadata for plotting\n",
    "output_times = data[\"times\"][2:end]\n",
    "output_x = data[\"grid\"]\n",
    "x0= X[:,:,1] # initial condition for rollout\n",
    "nsteps = length(output_times)\n",
    "nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "\n",
    "# training\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the size of the training set\n",
    "# Note that training set is not shuffled. It has eg all the zeros at the start\n",
    "n_train = 2000\n",
    "idx = rand(1:size(x_train,4),n_train)\n",
    "x_train = x_train[:,:,:,idx]\n",
    "y_train = y_train[idx]\n",
    "y_train_onehot = Flux.onehotbatch(y_train, 0:9)\n",
    "\n",
    "nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move data to gpu\n",
    "if use_gpu\n",
    "    x_train_gpu = gpu(x_train)\n",
    "    y_train_onehot_gpu = gpu(y_train_onehot)\n",
    "    y_train_gpu = gpu(y_train)\n",
    "    x_test_gpu = gpu(x_test)\n",
    "    y_test_onehot_gpu = gpu(y_test_onehot)\n",
    "    y_test_gpu = gpu(y_test)\n",
    "else\n",
    "    x_train_gpu = x_train\n",
    "    y_train_onehot_gpu = y_train_onehot\n",
    "    y_train_gpu = y_train\n",
    "    x_test_gpu = x_test\n",
    "    y_test_onehot_gpu = y_test_onehot\n",
    "    y_test_gpu = y_test\n",
    "end\n",
    "\n",
    "nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the Lenet v5 model -> http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf\n",
    "model = Chain(\n",
    "    Conv((5,5),1 => 6, relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((5,5),6 => 16, relu),\n",
    "    MaxPool((2,2)),\n",
    "    Flux.flatten,\n",
    "    Dense(256=>120,relu),\n",
    "    Dense(120=>84, relu),\n",
    "    Dense(84=>10, sigmoid),\n",
    "    softmax\n",
    ") \n",
    "\n",
    "if use_gpu\n",
    "    model_gpu = gpu(model)\n",
    "else\n",
    "    model_gpu = model\n",
    "end\n",
    "\n",
    "nothing\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and accuracy\n",
    "\n",
    "# Define the loss function that uses the cross-entropy to \n",
    "# measure the error by comparing model predictions of data \n",
    "# row \"x\" with true data from labels vector \"y\" in one hot encoding\n",
    "function loss(model, x, y_onehot)\n",
    "\treturn Flux.crossentropy(model(x),y_onehot)\n",
    "end\n",
    "\n",
    "# Function that measures the accuracy of\n",
    "# model on testing dataset\n",
    "function accuracy(model,x,y)\n",
    "\tmx=model(x)\n",
    "\tn=length(y)\n",
    "\treturn count((Flux.onecold(mx).-1) .== y)/n\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = model_gpu |>cpu\n",
    "#a1_cpu=accuracy(model,x_train[:,:,:,1:10],y_train[1:10])\n",
    "#mx=model(x_train[:,:,:,1:10])\n",
    "#mx_1c=Flux.onecold(mx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some tesing only\n",
    "# @time a1_gpu=accuracy(model_gpu,x_train_gpu,y_train_gpu)\n",
    "# @time a1_cpu=accuracy(model,x_train,y_train)\n",
    "# println(\"Accuracy on GPU: \",a1_gpu)\n",
    "# println(\"Accuracy on CPU: \",a1_cpu)\n",
    "# @time l1_gpu=loss(model_gpu,x_train_gpu,y_train_onehot_gpu)\n",
    "# @time l1_cpu=loss(model,x_train,y_train_onehot)\n",
    "# println(\"Loss on GPU: \",l1_gpu)\n",
    "# println(\"Loss on CPU: \",l1_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32-element DataLoader(::Tuple{CuArray{Float32, 4, CUDA.Mem.DeviceBuffer}, OneHotArrays.OneHotMatrix{UInt32, CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}}, shuffle=true, batchsize=64)\n",
       "  with first element:\n",
       "  (28×28×1×64 CuArray{Float32, 4, CUDA.Mem.DeviceBuffer}, 10×64 OneHotMatrix(::CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}) with eltype Bool,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setup data loader for training data\n",
    "# Assemble the training data\n",
    "if use_gpu\n",
    "\ttrain_data = Flux.DataLoader((x_train_gpu,y_train_onehot_gpu), shuffle=true, batchsize=64)\n",
    "else\n",
    "\ttrain_data = Flux.DataLoader((x_train,y_train_onehot), shuffle=true, batchsize=64)\n",
    "end\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy for training: 0.731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy for testing : 0.735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Loss for training    : 1.9271423\n",
      "   Loss for testing     : 1.9248906\n",
      "epoch: 2\n",
      "   Accuracy for training: 0.7965\n",
      "   Accuracy for testing : 0.8009\n",
      "   Loss for training    : 1.6718405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Loss for testing     : 1.669309\n",
      "epoch: 3\n",
      "   Accuracy for training: 0.847\n",
      "   Accuracy for testing : 0.8366\n",
      "   Loss for training    : 1.6163288\n",
      "   Loss for testing     : 1.6166949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy for training: 0.888\n",
      "   Accuracy for testing : 0.8821\n",
      "   Loss for training    : 1.5865014\n",
      "   Loss for testing     : 1.5919523\n",
      "epoch: 5\n",
      "   Accuracy for training: 0.915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy for testing : 0.9014\n",
      "   Loss for training    : 1.5627532\n",
      "   Loss for testing     : 1.5727644\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the ADAM optimizer with default settings\n",
    "optimizer = Flux.setup(Adam(),model_gpu)\n",
    "\n",
    "# Train the model\n",
    "# and display the accuracy on each\n",
    "# iteration\n",
    "for epoch in 1:5\n",
    "\tFlux.train!(loss, model_gpu, train_data, optimizer)\n",
    "    println(\"epoch: $(epoch)\") #NOTE: we careless with compute, rerunning model each time below\n",
    "    println(\"   Accuracy for training: $(accuracy(model_gpu,x_train_gpu,y_train_gpu))\")\n",
    "    println(\"   Accuracy for testing : $(accuracy(model_gpu,x_test_gpu,y_test_gpu))\")\n",
    "    println(\"   Loss for training    : $(loss(model_gpu,x_train_gpu,y_train_onehot_gpu))\")\n",
    "    println(\"   Loss for testing     : $(loss(model_gpu,x_test_gpu,y_test_onehot_gpu))\")\n",
    "\n",
    "end\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
