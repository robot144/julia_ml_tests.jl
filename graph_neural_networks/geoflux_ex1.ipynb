{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Convolutional Network with GeometrixFlux.jl\n",
    "\n",
    "This example is adapted from examples/gcm_with_Static_graph.jl in GeometrixFlux.jl. It is the first example that I try to run with this package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/src_nobackup/julia_ml_tests.jl.git/graph_neural_networks`\n"
     ]
    }
   ],
   "source": [
    "# Install packages - Needed only once   \n",
    "using Pkg\n",
    "Pkg.activate(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA\n",
    "using Flux\n",
    "using Flux: onehotbatch, onecold\n",
    "using Flux.Losses: logitcrossentropy\n",
    "using Flux.Data: DataLoader\n",
    "using GeometricFlux\n",
    "using GeometricFlux.Datasets\n",
    "using Graphs\n",
    "using GraphSignals\n",
    "using Parameters: @with_kw\n",
    "using ProgressMeter: Progress, next!\n",
    "using Statistics\n",
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some paramaters\n",
    "\n",
    "η = 0.01                # learning rate\n",
    "λ = 5f-4                # regularization paramater\n",
    "batch_size = 64         # batch size\n",
    "epochs = 200            # number of epochs\n",
    "seed = 0                # random seed\n",
    "cuda = true             # use GPU\n",
    "input_dim = 1433        # input dimension\n",
    "hidden_dim = 16         # hidden dimension\n",
    "target_dim = 7          # target dimension\n",
    "dataset = Cora          # dataset to train on\n",
    "\n",
    "nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `Planetoid` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `Planetoid` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/src_nobackup/machine_learning_tests.git/geoflux_ex1.ipynb:3"
     ]
    }
   ],
   "source": [
    "using GeometricFlux.Datasets\n",
    "\n",
    "function load_data(dataset, batch_size, train_repeats=512, test_repeats=32)\n",
    "    s, t = dataset[1].edge_index\n",
    "    g = Graphs.Graph(dataset[1].num_nodes)\n",
    "    for (i, j) in zip(s, t)\n",
    "        Graphs.add_edge!(g, i, j)\n",
    "    end\n",
    "\n",
    "    data = dataset[1].node_data\n",
    "    X, y = data.features, onehotbatch(data.targets, 1:7)\n",
    "    train_idx, test_idx = data.train_mask, data.val_mask\n",
    "\n",
    "    # (train_X, train_y) dim: (num_features, target_dim) × 2708 × train_repeats\n",
    "    train_X, train_y = repeat(X, outer=(1,1,train_repeats)), repeat(y, outer=(1,1,train_repeats))\n",
    "    # (test_X, test_y) dim: (num_features, target_dim) × 2708 × test_repeats\n",
    "    test_X, test_y = repeat(X, outer=(1,1,test_repeats)), repeat(y, outer=(1,1,test_repeats))\n",
    "\n",
    "    fg = FeaturedGraph(g)\n",
    "    train_loader = DataLoader((train_X, train_y), batchsize=batch_size, shuffle=true)\n",
    "    test_loader = DataLoader((test_X, test_y), batchsize=batch_size, shuffle=true)\n",
    "    return train_loader, test_loader, fg, train_idx, test_idx\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training on CPU\n",
      "└ @ Main /home/verlaan/src_nobackup/machine_learning_tests.git/geoflux_ex1.ipynb:10\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "Random.seed!(seed)\n",
    "\n",
    "# GPU config\n",
    "if cuda && CUDA.has_cuda()\n",
    "    device = gpu\n",
    "    @info \"Training on GPU\"\n",
    "else\n",
    "    device = cpu\n",
    "    @info \"Training on CPU\"\n",
    "end\n",
    "\n",
    "nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `Planetoid` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `Planetoid` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] load_data(dataset::Symbol, batch_size::Int64, train_repeats::Int64, test_repeats::Int64)\n",
      "   @ Main ~/src_nobackup/machine_learning_tests.git/geoflux_ex1.ipynb:5\n",
      " [2] load_data(dataset::Symbol, batch_size::Int64)\n",
      "   @ Main ~/src_nobackup/machine_learning_tests.git/geoflux_ex1.ipynb:5\n",
      " [3] top-level scope\n",
      "   @ ~/src_nobackup/machine_learning_tests.git/geoflux_ex1.ipynb:23"
     ]
    }
   ],
   "source": [
    "# Dataset \n",
    "\n",
    "function load_data(dataset, batch_size, train_repeats=256, test_repeats=32)\n",
    "    # (train_X, train_y) dim: (num_features, target_dim) × 140\n",
    "    train_X, train_y = map(x->Matrix(x), traindata(Planetoid(), dataset))\n",
    "    # (test_X, test_y) dim: (num_features, target_dim) × 1000\n",
    "    test_X, test_y = map(x->Matrix(x), testdata(Planetoid(), dataset))\n",
    "    g = graphdata(Planetoid(), dataset)\n",
    "    train_idx = train_indices(Planetoid(), dataset)\n",
    "    test_idx = test_indices(Planetoid(), dataset)\n",
    "\n",
    "    train_data = [(subgraph(FeaturedGraph(g, nf=train_X), train_idx), train_y) for _ in 1:train_repeats]\n",
    "    test_data = [(subgraph(FeaturedGraph(g, nf=test_X), test_idx), test_y) for _ in 1:test_repeats]\n",
    "    train_batch = Flux.batch(train_data)\n",
    "    test_batch = Flux.batch(test_data)\n",
    "\n",
    "    train_loader = DataLoader(train_batch, batchsize=batch_size, shuffle=true)\n",
    "    test_loader = DataLoader(test_batch, batchsize=batch_size, shuffle=true)\n",
    "    return train_loader, test_loader\n",
    "end\n",
    "\n",
    "\n",
    "GeometricFlux.Datasets.Planetoid() = PlanetoidDataset()\n",
    "\n",
    "# load Cora from Planetoid dataset\n",
    "train_loader, test_loader = load_data(:cora, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "model = Chain(\n",
    "    GCNConv(input_dim=>hidden_dim, relu),\n",
    "    GraphParallel(node_layer=Dropout(0.5)),\n",
    "    GCNConv(hidden_dim=>target_dim),\n",
    "    node_feature,\n",
    ") |> device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Loss: cross entropy with first layer L2 regularization \n",
    "l2norm(x) = sum(abs2, x)\n",
    "function model_loss(model, λ, batch)\n",
    "    loss = 0.f0\n",
    "    for (x, y) in batch\n",
    "        loss += logitcrossentropy(model(x), y)\n",
    "        loss += λ*sum(l2norm, Flux.params(model[1]))\n",
    "    end\n",
    "    return loss\n",
    "end\n",
    "\n",
    "function accuracy(model, batch::AbstractVector)\n",
    "    return mean(mean(onecold(softmax(cpu(model(x)))) .== onecold(cpu(y))) for (x, y) in batch)\n",
    "end\n",
    "\n",
    "accuracy(model, loader::DataLoader, device) = mean(accuracy(model, batch |> device) for batch in loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "function load_data(dataset, batch_size, train_repeats=512, test_repeats=32)\n",
    "    s, t = dataset[1].edge_index\n",
    "    g = Graphs.Graph(dataset[1].num_nodes)\n",
    "    for (i, j) in zip(s, t)\n",
    "        Graphs.add_edge!(g, i, j)\n",
    "    end\n",
    "\n",
    "    data = dataset[1].node_data\n",
    "    X, y = data.features, onehotbatch(data.targets, 1:7)\n",
    "    train_idx, test_idx = data.train_mask, data.val_mask\n",
    "\n",
    "    # (train_X, train_y) dim: (num_features, target_dim) × 2708 × train_repeats\n",
    "    train_X, train_y = repeat(X, outer=(1,1,train_repeats)), repeat(y, outer=(1,1,train_repeats))\n",
    "    # (test_X, test_y) dim: (num_features, target_dim) × 2708 × test_repeats\n",
    "    test_X, test_y = repeat(X, outer=(1,1,test_repeats)), repeat(y, outer=(1,1,test_repeats))\n",
    "\n",
    "    fg = FeaturedGraph(g)\n",
    "    train_loader = DataLoader((train_X, train_y), batchsize=batch_size, shuffle=true)\n",
    "    test_loader = DataLoader((test_X, test_y), batchsize=batch_size, shuffle=true)\n",
    "    return train_loader, test_loader, fg, train_idx, test_idx\n",
    "end\n",
    "\n",
    "\n",
    "## Loss: cross entropy with first layer L2 regularization \n",
    "l2norm(x) = sum(abs2, x)\n",
    "\n",
    "function model_loss(model, λ, X, y, idx)\n",
    "    loss = logitcrossentropy(model(X)[:,idx,:], y[:,idx,:])\n",
    "    loss += λ*sum(l2norm, Flux.params(model[1]))\n",
    "    return loss\n",
    "end\n",
    "\n",
    "accuracy(model, X::AbstractArray, y::AbstractArray, idx) =\n",
    "    mean(onecold(softmax(cpu(model(X))[:,idx,:])) .== onecold(cpu(y)[:,idx,:]))\n",
    "\n",
    "accuracy(model, loader::DataLoader, device, idx) =\n",
    "    mean(accuracy(model, X |> device, y |> device, idx) for (X, y) in loader)\n",
    "\n",
    "function train(; kws...)\n",
    "    # load hyperparamters\n",
    "    args = Args(; kws...)\n",
    "    args.seed > 0 && Random.seed!(args.seed)\n",
    "\n",
    "    # GPU config\n",
    "    if args.cuda && CUDA.has_cuda()\n",
    "        device = gpu\n",
    "        CUDA.allowscalar(false)\n",
    "        @info \"Training on GPU\"\n",
    "    else\n",
    "        device = cpu\n",
    "        @info \"Training on CPU\"\n",
    "    end\n",
    "\n",
    "    # load Cora from Planetoid dataset\n",
    "    train_loader, test_loader, fg, train_idx, test_idx = load_data(args.dataset(), args.batch_size)\n",
    "    \n",
    "    # build model\n",
    "    model = Chain(\n",
    "        WithGraph(fg, GCNConv(args.input_dim=>args.hidden_dim, relu)),\n",
    "        Dropout(0.5),\n",
    "        WithGraph(fg, GCNConv(args.hidden_dim=>args.target_dim)),\n",
    "    ) |> device\n",
    "\n",
    "    # Adam optimizer\n",
    "    opt = Adam(args.η)\n",
    "    \n",
    "    # parameters\n",
    "    ps = Flux.params(model)\n",
    "\n",
    "    # training\n",
    "    train_steps = 0\n",
    "    @info \"Start Training, total $(args.epochs) epochs\"\n",
    "    for epoch = 1:args.epochs\n",
    "        @info \"Epoch $(epoch)\"\n",
    "        progress = Progress(length(train_loader))\n",
    "\n",
    "        for (X, y) in train_loader\n",
    "            X, y, device_idx = X |> device, y |> device, train_idx |> device\n",
    "            loss, back = Flux.pullback(() -> model_loss(model, args.λ, X, y, device_idx), ps)\n",
    "            train_acc = accuracy(model, train_loader, device, train_idx)\n",
    "            test_acc = accuracy(model, test_loader, device, test_idx)\n",
    "            grad = back(1f0)\n",
    "            Flux.Optimise.update!(opt, ps, grad)\n",
    "\n",
    "            # progress meter\n",
    "            next!(progress; showvalues=[\n",
    "                (:loss, loss),\n",
    "                (:train_accuracy, train_acc),\n",
    "                (:test_accuracy, test_acc)\n",
    "            ])\n",
    "\n",
    "            train_steps += 1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return model, args\n",
    "end\n",
    "\n",
    "model, args = train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
